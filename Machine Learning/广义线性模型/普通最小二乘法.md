高斯于1823年在误差$e_1,e_2,...,e_n$独立同分布的假定下，证明了最小二乘方法的一个最优性质：在所有无偏的线性估计类中,最小二乘方法是其中方差最小的！

$$
{h_{\theta}}\left( x \right)={\theta^{T}}X={\theta_{0}}{x_{0}}+{\theta_{1}}{x_{1}}+{\theta_{2}}{x_{2}}+...+{\theta_{n}}{x_{n}} {\tag1}
$$

### 损失函数

$$
J\left( {\theta_{0}},{\theta_{1}}...{\theta_{n}} \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{{{\left( h_{\theta} \left({x}^{\left( i \right)} \right)-{y}^{\left( i \right)} \right)}^{2}}}=\frac{1}{2}({X\theta} -{y})^T({X\theta} - {y})
$$

损失函数是“二乘”，目标是最小化损失函数，即“最小二乘”。

### **推导过程**

将损失函数的向量表达形式转为矩阵表达形式，则有

$$
J(\theta )=\frac{1}{2}{{\left( X\theta -y\right)}^{2}}\tag 2
$$

其中$X$为$m$行$n$列的矩阵（$m$为样本个数，$n$为特征个数），$\theta$为$n$行1列的矩阵，$y$为$m$行1列的矩阵，对$J(\theta )$进行如下变换

$$
\begin{aligned} J(\theta )&=\frac{1}{2}{{\left( X\theta -y\right)}^{T}}\left( X\theta -y \right)\\ & =\frac{1}{2}\left( {{\theta }^{T}}{{X}^{T}}-{{y}^{T}} \right)\left(X\theta -y \right)\\ &=\frac{1}{2}\left( {{\theta }^{T}}{{X}^{T}}X\theta -{{\theta}^{T}}{{X}^{T}}y-{{y}^{T}}X\theta -{{y}^{T}}y \right) \end{aligned} \tag 3
$$

接下来对$J(\theta )$求偏导，需要用到以下几个矩阵的求导法则:

$$
\frac{dAB}{dB}={{A}^{T}} \tag 4
$$

所以有:

$$
\begin{aligned} \frac{\partial J\left( \theta \right)}{\partial \theta } & =\frac{1}{2}\left(2{{X}^{T}}X\theta -{{X}^{T}}y -{}({{y}^{T}}X )^{T}-0 \right) \\ &
=\frac{1}{2}\left(2{{X}^{T}}X\theta -{{X}^{T}}y -{{X}^{T}}y -0 \right) \\&
={{X}^{T}}X\theta -{{X}^{T}}y \end{aligned} \tag 5
$$

令$\frac{\partial J\left( \theta \right)}{\partial \theta }=0$，则有 $\theta ={{\left( {X^{T}}X \right)}^{-1}}{X^{T}}y$

# 实现

## 梯度下降法实现

1、 **批量梯度下降**

一般形式：

$$
\begin{aligned} \theta_j =&    \theta_j-\alpha\frac \partial {\partial \theta_j}J(\theta_0,\theta_1,...,\theta_m) \\ =&\theta_j-\alpha\frac \partial {\partial\theta_j}\frac 1 {2m} \sum_{i=1}^m(h_{\theta}(X^{(i)})-y^{(i)})^2  \\ =&\theta_j-\alpha\frac 1 m \sum_{i=1}^m((h_{\theta}(X^{(i)})-y^{(i)})·X_j^{(i)}) \end{aligned}
$$

当n>=1时，

$$
{{\theta  }_{0}}:={{\theta }{0}}-a\frac{1}{m}\sum\limits_{i=1}^{m}{({{h}{\theta }}({{x}^{(i)}})-{{y}^{(i)}})}x{0}^{(i)}
$$

$$
{{\theta }_{1}}:={{\theta }_{1}}-a\frac{1}{m}\sum\limits_{i=1}^{m}{({{h}{\theta }}({{x}^{(i)}})-{{y}^{(i)}})}x{1}^{(i)}
$$

$$
⁍
$$

矩阵形式：  

$$
\theta= \theta -\frac 1 m \alpha{X}^T({X\theta} -{Y})
$$

其中$\alpha$为步长

2、**随机梯度下降** 

$$
\theta=\theta- \alpha X_i^T(X_i\theta-Y_i)
$$

3、 **小批量梯度下降**

$$
\theta=\theta-\frac 1 M \alpha X_{i-j}^T(X_{i-j}\theta-Y_{i-j})
$$

其中 $M$为`batch_size`